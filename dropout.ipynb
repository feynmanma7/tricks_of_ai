{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Without Dropout\n",
    "\n",
    "> $y = WX$\n",
    "\n",
    "\n",
    "# 1. Vanilla Dropout\n",
    "\n",
    "\n",
    "## Training\n",
    "\n",
    "$r \\sim Ber(p)$\n",
    "\n",
    "$V = X*r$\n",
    "\n",
    "$y = WV$\n",
    "\n",
    "$\\mathbb{E}(y) = \\mathbb{E}(WV) = W \\mathbb{E}(Xr) = WX \\mathbb{E}(r) = WX p$\n",
    "\n",
    "## Test\n",
    "\n",
    "Keep all of the nodes, for training data $X$, the predicted $y$ is $\\tilde{y} = WX$\n",
    "\n",
    "$\\mathbb{E}(\\tilde{y}) = WX$\n",
    "\n",
    "To keep **the expectation of output** of trained model is identical in the training and test phrase, the keep ratio $p$ must be multiplied.\n",
    "\n",
    "> $y = WX * p$\n",
    "\n",
    "# 2. Inverted Dropout\n",
    "\n",
    "## Test\n",
    "\n",
    "To keep the test phrase without modified, $y = WX$, $\\mathbb{E}(y) = WX$.\n",
    "\n",
    "## Training\n",
    "\n",
    "Note $p$ is the keep ratio.\n",
    "\n",
    "Let $y = WX*r / p$, thus $\\mathbb{E}(y) = WX * p / p = WX$, the expecation of the output of the model is same between training and test phrase.\n",
    "\n",
    "Thus, \n",
    "\n",
    "> $y = WX * Ber(p) / p$ in the training phrase, \n",
    "\n",
    "> $y = WX$ in the test phrase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
